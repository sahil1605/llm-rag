# API Reference (Minimal)

## POST /upload
Content-Type: multipart/form-data

- fields:
  - `files[]` (or `files`): one or more files (.pdf/.md/.txt)
  - `session_id` (optional): reuse an existing session
- response:
  - `{ "session_id": "...", "files": [{"filename":"...","size":123}] }`

## POST /load
Content-Type: application/json

- body: `{ "session_id": "...", "chunk_size": 800, "chunk_overlap": 120 }`
- response: `{ "indexed_chunks": 42, "status": "ok" }`

## POST /ask
Content-Type: application/json

- body: `{ "session_id": "...", "question": "...", "top_k": 4, "include_sources": true }`
- response: `{ "answer": "...", "sources": [...], "latency_ms": 123 }`

Behavior:
- If `OLLAMA_MODEL` is set, the answer is generated by the LLM with retrieved context.
- Otherwise the answer is the concatenation of top snippets (retrieval-only fallback).
